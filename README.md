# 🔥【Python网络爬虫基础入门】数据解析三种方法re、bs4、Xpath从入门到实战。
&emsp;&emsp;正所谓爬虫写的好，牢饭吃到饱，爬取网易云音乐、爬取B站视频想必大家都不陌生，那么我们如何去实现呢？<br>
&emsp;&emsp;看到 AI Studio中的众多数据集，你是否有想过怎样**方便快捷**的收集自己的**数据集**呢？
<br>&emsp;&emsp;你又是否有想过在一个人的深夜，如何收集众多的优美图片

**那么就请你看完这篇项目，你一定会有所收获的（手动狗头）**
>先看后赞，养成习惯

>folk收藏，人生辉煌

![](https://ai-studio-static-online.cdn.bcebos.com/f907ebf2dec34f81945f0479f0cc89fbc9789653df6a4d8f9af5e322e05eeb95)

# 一、什么是网络爬虫
百度百科给的介绍如下：
>&emsp;&emsp;网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。

&emsp;&emsp;通俗来讲，假如你需要互联网上的信息，如商品价格，图片视频资源等，但你又不想或者不能自己一个一个自己去打开网页收集，这时候你便写了一个程序，让程序按照你指定好的规则去互联网上收集信息，这便是爬虫，我们熟知的**百度，谷歌等搜索引擎背后其实也是一个巨大的爬虫。**

## **爬虫合法吗？**
&emsp;&emsp;🎯可能很多小伙伴都会又这个疑问，首先爬虫是一门技术，技术应该是中立的，合不合法其实取决于你使用目的，是由爬虫背后的人来决定的，而不是爬虫来决定的。另外我们爬取信息的时候也可以稍微**‘克制’**一下，能拿到自己想要的信息就够了，没必要对着人家一直撸，看看我们的12306都被逼成啥样了🤧🤧🤧。
&emsp;&emsp;一般来说只要不影响人家网站的正常运转，也不是出于商业目的，人家一般也就只会封下的IP，账号之类的，不至于法律风险👌。
&emsp;&emsp;其实大部分网站都会有一个robots协议，在网站的根目录下会有个robots.txt的文件，里面写明了网站里面哪些内容可以抓取，哪些不允许。

然后我们以百度搜索为例子：[https://www.baidu.com/robots.txt](https://www.baidu.com/robots.txt) 
<br>（我们只需要在网页后缀加上/robots.txt）

![](https://ai-studio-static-online.cdn.bcebos.com/689dec2d3ae14df6a4e127e5181a60a91e9cd1dbcfd14d1db9660f25657478dd)
<br>&emsp;&emsp;当然robots协议本身也只是一个业内的约定，是不具有法律意义的，所以遵不遵守呢也只能取决于用户本身的底线了。（懂得都懂）

# 二、网络爬虫能做什么

&emsp;&emsp;上面说了一大堆，可能也没说清楚爬虫究竟是什么。没关系，我们举几个例子来看。
<br>&emsp;&emsp;比如，学校经常在官网上发布一些比较重要的通知，我不想每天都花费精力去看官网，却又想当有新通知的时候，就能知道，并看到它。
<br>&emsp;&emsp;这种时候，就需要爬虫来帮忙咯。写一个程序，让它**每半个小时或一个小时**就去访问一次官网，检查有没有新的通知，如果没有，就什么都不做，等待下次检查，如果有，就将新通知从网页中提取出来，保存，并发邮件告诉我们通知的内容，然后继续等待即可。
<br>&emsp;&emsp;假设，最近有点闲了，想看看电影，但又不想看烂片。于是，默默打开了豆瓣，上面有电影评分嘛，还有影评。我想要获取所以评分在８分以上的电影名称、简介以及该电影的部分热评，**从中选出想看的出来**。
<br>&emsp;&emsp;这个时候，一个小小的爬虫就能轻轻松松地从一堆电影中**找出符合要求的保存下来**，不用费神地一个个去瞅了。如果你还会自然语言处理和机器学习，那就更棒了，或许你可以直接对这些数据进行分析，让程序匹配出你感兴趣的电影来。（当然了，举例子嘛，现实生活中，显然投入和产出不成正比= =看个电影哪那么麻烦orz）
<br>&emsp;&emsp;🎯再比如，采集京东、淘宝的商品评论信息啦，采集招聘网站的企业职位信息啦，采集微博信息啦，或者只是简单地爬一些**美女图片**啦……各种情况，采什么，看需求吧。

# 三、开始实战

&emsp;&emsp;为了方便，我使用一块一个的小案例进行演示：
